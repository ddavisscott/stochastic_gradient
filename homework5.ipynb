{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid Function\n",
    "def sig(w,x):\n",
    "    d=np.dot(x,w)\n",
    "    t_pred = 1/(1+np.exp(-d))\n",
    "    return t_pred\n",
    "\n",
    "# Log Likelihood\n",
    "def loglikelihood(w,x,t):\n",
    "    l=0\n",
    "    for i in range(len(t)):\n",
    "        l += t[i]*np.log(sig(w,x[i,:]))+(1-t[i])*np.log(1-sig(w,x[i,:]))\n",
    "    return l\n",
    "\n",
    "# Derivative of the Loss Function\n",
    "def dLdW(w,x,t):\n",
    "    t_pred = sig(w,x)\n",
    "    return (t_pred-t)*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scottdavis/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Outcome'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d8ec989977fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Split Unnormalized Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Outcome'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Outcome'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m         )\n\u001b[1;32m   4104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3912\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3913\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3914\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3944\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3945\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3946\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3947\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5338\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5340\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not found in axis\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5341\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5342\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Outcome'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Read datasets and make normalized version\n",
    "dataset = pd.read_csv('diabetes.csv')\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(dataset)\n",
    "scaler.data_max_\n",
    "column_names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
    "normalized_dataset = pd.DataFrame(scaler.transform(dataset), columns=column_names)\n",
    "\n",
    "# Split Unnormalized Data\n",
    "X = dataset.drop('Outcome', axis=1)\n",
    "t = dataset['Outcome']\n",
    "train_X, test_X, train_t, test_t = train_test_split(X, t, test_size=0.2, stratify=t)\n",
    "del dataset, X, t\n",
    "column_names = ['Bias', 'Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "train_X = pd.DataFrame(np.concatenate((np.ones(train_X.shape[0]).reshape(-1,1), train_X.values), axis=1),columns = column_names)\n",
    "train_t = pd.DataFrame(train_t.values,columns = ['Outcome'])\n",
    "test_X = pd.DataFrame(np.concatenate((np.ones(test_X.shape[0]).reshape(-1,1), test_X.values), axis=1),columns = column_names)\n",
    "test_t = pd.DataFrame(test_t.values,columns = ['Outcome'])\n",
    "\n",
    "train_X = train_X.values\n",
    "train_t = train_t.values\n",
    "test_X = test_X.values\n",
    "test_t = test_t.values\n",
    "\n",
    "l = train_X.shape[0]\n",
    "X = np.concatenate((train_X,test_X), axis=0)\n",
    "scaler.fit(X)\n",
    "scaler.data_max_\n",
    "X = scaler.transform(X)\n",
    "norm_train_X = X[0:l,:]\n",
    "norm_test_X = X[l:,:]\n",
    "norm_train_t = train_t\n",
    "norm_test_t = test_t\n",
    "\n",
    "# # Split Normalized Data\n",
    "# X = normalized_dataset.drop('Outcome', axis=1)\n",
    "# t = normalized_dataset['Outcome']\n",
    "# norm_train_X, norm_test_X, norm_train_t, norm_test_t = train_test_split(X, t, test_size=0.2, stratify=t)\n",
    "# del normalized_dataset, X, t\n",
    "# norm_train_X = pd.DataFrame(norm_train_X.values,columns = column_names)\n",
    "# norm_train_t = pd.DataFrame(norm_train_t.values,columns = ['Outcome'])\n",
    "# norm_test_X = pd.DataFrame(norm_test_X.values,columns = column_names)\n",
    "# norm_test_t = pd.DataFrame(norm_test_t.values,columns = ['Outcome'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "Implement stochastic gradient descent for logistic regression (see equation 4.91, but update for each example in turn rather than summing the gradients over all examples) and do the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.a.\n",
    "Apply your SGD algorithm to the un-normalized training set. Keep track of the log-likelihood of the training set, and run until the log-likelihood seems to be converging. Experiment a little bit with the step-size. What step sizes seem to lead to faster convergence? How long does the convergence take (measured in wall-clock time and epochs). What is your error rates and average log-likelihood on the training data and on the test data? (The average log-likelihood divided by the number of examples.) What features are given the highest positive weights? Which features are given the largest negative weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b617b6902540>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Initialize weights and Likelihood values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlikelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_X' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize weights and Likelihood values\n",
    "w = np.random.random(train_X.shape[1])\n",
    "likelihood = np.array([])\n",
    "ind = np.array([])\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "threshold = 1e-4\n",
    "nsteps = train_t.shape[0]\n",
    "alpha = 1e-4\n",
    "l_old = -np.inf\n",
    "l_new = -np.random.random(1)\n",
    "start = time.time()\n",
    "epochs = 0\n",
    "while (abs(l_old - l_new) > threshold) or (np.isnan(l_old) or np.isnan(l_new)):\n",
    "    for i in range(nsteps):\n",
    "        w = w - alpha * dLdW(w.reshape(-1), train_X[i,:], train_t[i])\n",
    "    epochs += 1\n",
    "    ind = np.append(ind,epochs)\n",
    "    l_old = l_new\n",
    "    l_new = loglikelihood(w.reshape(-1),train_X,train_t)/nsteps\n",
    "    likelihood = np.append(likelihood,l_new)\n",
    "end = time.time()\n",
    "runtime = end-start\n",
    "pred_train_t = (sig(w.reshape(-1),train_X) > 0.5).astype(int)\n",
    "pred_test_t = (sig(w.reshape(-1),test_X) > 0.5).astype(int)\n",
    "plt.plot(ind,likelihood,'-')\n",
    "print('Epochs:', epochs)\n",
    "print('Runtime:', runtime)\n",
    "print('Log Likelihood of Training Data:', loglikelihood(w.reshape(-1), train_X, train_t)/nsteps)\n",
    "print('Log Likelihood of Test Set:', loglikelihood(w.reshape(-1), test_X, test_t)/nsteps)\n",
    "print('Predicted Training Labels:', pred_train_t)\n",
    "print('Predicted Test Labels:', pred_test_t)\n",
    "print('Error on Training Data:', mean_squared_error(train_t, pred_train_t))\n",
    "print('Error on Test Data:', mean_squared_error(test_t, pred_test_t))\n",
    "w = pd.DataFrame(w.reshape(1,-1),columns = column_names)\n",
    "\n",
    "\n",
    "del likelihood, ind, threshold, nsteps, alpha, epochs, l_old, l_new, i, pred_train_t, pred_test_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bias</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.153285</td>\n",
       "      <td>0.247829</td>\n",
       "      <td>0.028142</td>\n",
       "      <td>-0.044244</td>\n",
       "      <td>0.013437</td>\n",
       "      <td>-0.013147</td>\n",
       "      <td>-0.008274</td>\n",
       "      <td>0.240614</td>\n",
       "      <td>-0.041585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Bias  Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin  \\\n",
       "0 -0.153285     0.247829  0.028142      -0.044244       0.013437 -0.013147   \n",
       "\n",
       "        BMI  DiabetesPedigreeFunction       Age  \n",
       "0 -0.008274                  0.240614 -0.041585  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the weights\n",
    "w.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.b.\n",
    "Apply your SGD algorithm to the normalized training set. You can use a good step-size from the previous part. Report the log-likelihoods and error rates on the training and test sets. Are the learned weights similar? Are the learned hypotheses similar after taking into account the rescaling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6564888] [-0.65638953]\n",
      "Runtime: 4.080625295639038\n",
      "Epochs: 169\n",
      "Log Likelihood of Training Data: [-0.65638953]\n",
      "Log Likelihood of Test Set: [-0.16594318]\n",
      "Predicted Training Labels: [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1]\n",
      "Predicted Test Labels: [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0]\n",
      "Error on Training Data: 0.34039087947882735\n",
      "Error on Test Data: 0.37012987012987014\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize weights and Likelihood values\n",
    "w = np.random.random(norm_train_X.shape[1])\n",
    "likelihood = np.array([])\n",
    "ind = np.array([])\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "threshold = 1e-4\n",
    "nsteps = norm_train_t.shape[0]\n",
    "alpha = 1e-4\n",
    "epochs = 0\n",
    "l_old = -np.inf\n",
    "l_new = -np.random.random(1)\n",
    "start = time.time()\n",
    "# for e in range(200):\n",
    "while (abs(l_old - l_new) > threshold) or (np.isnan(l_old) or np.isnan(l_new)):\n",
    "    for i in range(nsteps):\n",
    "        w = w - alpha * dLdW(w.reshape(-1), norm_train_X[i,:], norm_train_t[i])\n",
    "    epochs += 1\n",
    "    ind = np.append(ind,epochs)\n",
    "    l_old = l_new\n",
    "    l_new = loglikelihood(w.reshape(-1),norm_train_X,norm_train_t)/nsteps\n",
    "    likelihood = np.append(likelihood,l_new)\n",
    "end = time.time()\n",
    "print(l_old, l_new)\n",
    "print('Runtime:', end-start)\n",
    "pred_train_t = (sig(w.reshape(-1),norm_train_X) > 0.5).astype(int)\n",
    "pred_test_t = (sig(w.reshape(-1),norm_test_X) > 0.5).astype(int)\n",
    "plt.plot(ind,likelihood,'-')\n",
    "print('Epochs:', epochs)\n",
    "print('Log Likelihood of Training Data:', loglikelihood(w.reshape(-1), norm_train_X, norm_train_t)/nsteps)\n",
    "print('Log Likelihood of Test Set:', loglikelihood(w.reshape(-1), norm_test_X, norm_test_t)/nsteps)\n",
    "print('Predicted Training Labels:', pred_train_t)\n",
    "print('Predicted Test Labels:', pred_test_t)\n",
    "print('Error on Training Data:', mean_squared_error(norm_train_t, pred_train_t))\n",
    "print('Error on Test Data:', mean_squared_error(norm_test_t, pred_test_t))\n",
    "w = pd.DataFrame(w.reshape(1,-1),columns = column_names)\n",
    "\n",
    "\n",
    "del likelihood, ind, threshold, nsteps, alpha, epochs, l_old, l_new, i, pred_train_t, pred_test_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bias</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.243043</td>\n",
       "      <td>0.030812</td>\n",
       "      <td>-0.496254</td>\n",
       "      <td>-0.595068</td>\n",
       "      <td>0.460866</td>\n",
       "      <td>0.50018</td>\n",
       "      <td>-0.017277</td>\n",
       "      <td>0.282937</td>\n",
       "      <td>0.550184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Bias  Pregnancies   Glucose  BloodPressure  SkinThickness  Insulin  \\\n",
       "0  0.243043     0.030812 -0.496254      -0.595068       0.460866  0.50018   \n",
       "\n",
       "        BMI  DiabetesPedigreeFunction       Age  \n",
       "0 -0.017277                  0.282937  0.550184  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "First apply a decision tress classifier (we recommend the one with scikit learn) on the training set. Experiment with different maximum depths, and report their error rates on the training and test data. Also report the training times required. Should the training or test set accuracies be the same on the unnormalized data as the normalized data? Why or why not? Next, apply a random forrest learner  to the training data. Try a few different numbers of trees (perhaps 5, 20, and 100). Report the training and test accuracies of your forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read datasets and make normalized version\n",
    "dataset = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Split Unnormalized Data\n",
    "X = dataset.drop('Outcome', axis=1)\n",
    "t = dataset['Outcome']\n",
    "train_X, test_X, train_t, test_t = train_test_split(X, t, test_size=0.2, stratify=t)\n",
    "del dataset, X, t\n",
    "column_names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "train_X = pd.DataFrame(train_X.values,columns = column_names)\n",
    "train_t = pd.DataFrame(train_t.values,columns = ['Outcome'])\n",
    "test_X = pd.DataFrame(test_X.values,columns = column_names)\n",
    "test_t = pd.DataFrame(test_t.values,columns = ['Outcome'])\n",
    "\n",
    "train_X = train_X.values\n",
    "train_t = train_t.values\n",
    "test_X = test_X.values\n",
    "test_t = test_t.values\n",
    "\n",
    "l = train_X.shape[0]\n",
    "X = np.concatenate((train_X,test_X), axis=0)\n",
    "scaler.fit(X)\n",
    "scaler.data_max_\n",
    "X = scaler.transform(X)\n",
    "norm_train_X = X[0:l,:]\n",
    "norm_test_X = X[l:,:]\n",
    "norm_train_t = train_t\n",
    "norm_test_t = test_t\n",
    "\n",
    "# # Split Normalized Data\n",
    "# X = normalized_dataset.drop('Outcome', axis=1)\n",
    "# t = normalized_dataset['Outcome']\n",
    "# norm_train_X, norm_test_X, norm_train_t, norm_test_t = train_test_split(X, t, test_size=0.2, stratify=t)\n",
    "# del normalized_dataset, X, t\n",
    "# norm_train_X = pd.DataFrame(norm_train_X.values,columns = column_names)\n",
    "# norm_train_t = pd.DataFrame(norm_train_t.values,columns = ['Outcome'])\n",
    "# norm_test_X = pd.DataFrame(norm_test_X.values,columns = column_names)\n",
    "# norm_test_t = pd.DataFrame(norm_test_t.values,columns = ['Outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 5\n",
      "Training Time: 0.00821828842163086\n",
      "Training Error: 0.1482084690553746\n",
      "Test Error: 0.2532467532467532\n",
      "Max Depth: 10\n",
      "Training Time: 0.010079383850097656\n",
      "Training Error: 0.014657980456026058\n",
      "Test Error: 0.3051948051948052\n",
      "Max Depth: 15\n",
      "Training Time: 0.008715391159057617\n",
      "Training Error: 0.0\n",
      "Test Error: 0.3051948051948052\n",
      "Max Depth: 20\n",
      "Training Time: 0.009923934936523438\n",
      "Training Error: 0.0\n",
      "Test Error: 0.2792207792207792\n"
     ]
    }
   ],
   "source": [
    "# Unnormalized Data Sets\n",
    "for i in range(4,20,5):\n",
    "    start = time.time()\n",
    "    tree = DecisionTreeClassifier(max_depth=i+1)\n",
    "    tree.fit(train_X, train_t)\n",
    "    end = time.time()\n",
    "    pred_train_t = tree.predict(train_X)\n",
    "    pred_test_t = tree.predict(test_X)\n",
    "    print(\"Max Depth:\", i+1)\n",
    "    print(\"Training Time:\", end-start)\n",
    "    print(\"Training Error:\", mean_squared_error(train_t, pred_train_t))\n",
    "    print(\"Test Error:\", mean_squared_error(test_t, pred_test_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 5\n",
      "Training Time: 0.008011341094970703\n",
      "Training Error: 0.1482084690553746\n",
      "Test Error: 0.24025974025974026\n",
      "Max Depth: 10\n",
      "Training Time: 0.010040044784545898\n",
      "Training Error: 0.014657980456026058\n",
      "Test Error: 0.2792207792207792\n",
      "Max Depth: 15\n",
      "Training Time: 0.009317874908447266\n",
      "Training Error: 0.0\n",
      "Test Error: 0.3051948051948052\n",
      "Max Depth: 20\n",
      "Training Time: 0.009448528289794922\n",
      "Training Error: 0.0\n",
      "Test Error: 0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "# Normalized Data Sets\n",
    "for i in range(4,20,5):\n",
    "    start = time.time()\n",
    "    tree = DecisionTreeClassifier(max_depth=i+1)\n",
    "    tree.fit(norm_train_X, norm_train_t)\n",
    "    end = time.time()\n",
    "    pred_train_t = tree.predict(norm_train_X)\n",
    "    pred_test_t = tree.predict(norm_test_X)\n",
    "    print(\"Max Depth:\", i+1)\n",
    "    print(\"Training Time:\", end-start)\n",
    "    print(\"Training Error:\", mean_squared_error(norm_train_t, pred_train_t))\n",
    "    print(\"Test Error:\", mean_squared_error(norm_test_t, pred_test_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Trees: 5\n",
      "Training Time: 0.037393808364868164\n",
      "Training Error: 0.03745928338762215\n",
      "Test Error: 0.2922077922077922\n",
      "Number of Trees: 20\n",
      "Training Time: 0.09646320343017578\n",
      "Training Error: 0.009771986970684038\n",
      "Test Error: 0.23376623376623376\n",
      "Number of Trees: 100\n",
      "Training Time: 0.2305753231048584\n",
      "Training Error: 0.0\n",
      "Test Error: 0.22077922077922077\n"
     ]
    }
   ],
   "source": [
    "ntrees = [5, 20, 100]\n",
    "\n",
    "for n in ntrees:\n",
    "    start = time.time()\n",
    "    forest = RandomForestClassifier(n_estimators=n)\n",
    "    forest.fit(train_X, train_t.reshape(-1))\n",
    "    end = time.time()\n",
    "    pred_train_t = forest.predict(train_X)\n",
    "    pred_test_t = forest.predict(test_X)\n",
    "    print(\"Number of Trees:\", n)\n",
    "    print(\"Training Time:\", end-start)\n",
    "    print(\"Training Error:\", mean_squared_error(train_t, pred_train_t))\n",
    "    print(\"Test Error:\", mean_squared_error(test_t, pred_test_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Trees: 5\n",
      "Training Time: 0.014598369598388672\n",
      "Training Error: 0.03257328990228013\n",
      "Test Error: 0.2662337662337662\n",
      "Number of Trees: 20\n",
      "Training Time: 0.012556076049804688\n",
      "Training Error: 0.03257328990228013\n",
      "Test Error: 0.2987012987012987\n",
      "Number of Trees: 100\n",
      "Training Time: 0.011200189590454102\n",
      "Training Error: 0.03257328990228013\n",
      "Test Error: 0.22077922077922077\n"
     ]
    }
   ],
   "source": [
    "for n in ntrees:\n",
    "    start = time.time()\n",
    "    forest = RandomForestClassifier(n_estimators=5)\n",
    "    forest.fit(norm_train_X, norm_train_t.reshape(-1))\n",
    "    end = time.time()\n",
    "    pred_train_t = forest.predict(norm_train_X)\n",
    "    pred_test_t = forest.predict(norm_test_X)\n",
    "    print(\"Number of Trees:\", n)\n",
    "    print(\"Training Time:\", end-start)\n",
    "    print(\"Training Error:\", mean_squared_error(norm_train_t, pred_train_t))\n",
    "    print(\"Test Error:\", mean_squared_error(norm_test_t, pred_test_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4\n",
    "Scikit learn has a neural_network.MLPClassifier module, use that or something similar to train up a neural network on your normalized training set. Experiment a bit with the number of layers (say 1-4) and number of nodes on each layer (say 10 to 100). Report the training time and accuracies on the training set and test set. Neural network packages tend to have many tunable parameters. Explore the effects for them on the running time and goodness of the produced hypothesis. Some of the more interesting candidates for exploration might be momentum, solver, and alpha (the L2 penalty parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Time: 2.4983204555511476\n",
      "Average Training Accuracy: 0.7212540716612369\n",
      "Average Test Accuracy: 0.7068831168831174\n"
     ]
    }
   ],
   "source": [
    "avg_runtime = np.array([])\n",
    "avg_train_accuracy = np.array([])\n",
    "avg_test_accuracy = np.array([])\n",
    "for i in range(100):\n",
    "    start = time.time()\n",
    "    nn = MLPClassifier(hidden_layer_sizes=(100,4), max_iter=2000)\n",
    "    nn.fit(norm_train_X, norm_train_t.reshape(-1))\n",
    "    end = time.time()\n",
    "    avg_runtime = np.append(avg_runtime, end-start)\n",
    "    pred_train_t = nn.predict(norm_train_X)\n",
    "    pred_test_t = nn.predict(norm_test_X)\n",
    "    avg_train_accuracy = np.append(avg_train_accuracy, 1-mean_squared_error(norm_train_t, pred_train_t))\n",
    "    avg_test_accuracy = np.append(avg_test_accuracy, 1-mean_squared_error(norm_test_t, pred_test_t))\n",
    "\n",
    "print(\"Average Training Time:\", sum(avg_runtime)/100)\n",
    "print(\"Average Training Accuracy:\", sum(avg_train_accuracy)/100)\n",
    "print(\"Average Test Accuracy:\", sum(avg_test_accuracy)/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "nn = MLPClassifier(hidden_layer_sizes=(100,4), max_iter=2000)\n",
    "nn.fit(norm_train_X, norm_train_t.reshape(-1))\n",
    "end = time.time()\n",
    "avg_runtime = np.append(avg_runtime, end-start)\n",
    "pred_train_t = nn.predict(norm_train_X)\n",
    "pred_test_t = nn.predict(norm_test_X)\n",
    "avg_train_accuracy = np.append(avg_train_accuracy, 1-mean_squared_error(norm_train_t, pred_train_t))\n",
    "avg_test_accuracy = np.append(avg_test_accuracy, 1-mean_squared_error(norm_test_t, pred_test_t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
